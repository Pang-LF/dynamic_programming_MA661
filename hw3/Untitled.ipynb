{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(self):\n",
    "        next_value_table = [[0.00] * self.env.width\n",
    "                                    for _ in range(self.env.height)]\n",
    "        # Bellman Expectation Equation for the every states\n",
    "        for state in self.env.get_all_states():\n",
    "            value = 0.0\n",
    "            for action in self.env.possible_actions:\n",
    "                next_state = self.env.state_after_action(state, action)\n",
    "                reward = self.env.get_reward(state, action)\n",
    "                next_value = self.get_value(next_state)\n",
    "                value += (self.get_policy(state)[action] *\n",
    "                          (reward + self.discount_factor * next_value))\n",
    "            next_value_table[state[0]][state[1]] = round(value, 2)\n",
    "        self.value_table = next_value_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(self):\n",
    "        next_policy = self.policy_table\n",
    "        for state in self.env.get_all_states():\n",
    "            value = -99999\n",
    "            max_index = []\n",
    "            result = [0.0, 0.0, 0.0, 0.0,0.0]  # initialize the policy\n",
    "\n",
    "            # for every actions, calculate\n",
    "            # [reward + (discount factor) * (next state value function)]\n",
    "            for index, action in enumerate(self.env.possible_actions):\n",
    "                next_state = self.env.state_after_action(state, action)\n",
    "                reward = self.env.get_reward(state, action)\n",
    "                next_value = self.get_value(next_state)\n",
    "                temp = reward + self.discount_factor * next_value\n",
    "                if temp == value:\n",
    "                    max_index.append(index)\n",
    "                elif temp > value:\n",
    "                    value = temp\n",
    "                    max_index.clear()\n",
    "                    max_index.append(index)\n",
    "\n",
    "            # probability of action\n",
    "            prob = 1 / len(max_index)\n",
    "\n",
    "            for index in max_index:\n",
    "                result[index] = prob\n",
    "\n",
    "            next_policy[state[0]][state[1]] = result\n",
    "\n",
    "        self.policy_table = next_policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
